{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose: to create a game environment: deck of cards, player draws cards, needs to discard if has more than hand size limit. \n",
    "\n",
    "Thenumber of cards in the deck of each set, along with the goal, and the hand size, are parameters\n",
    "\n",
    "we will give rewards for getting a set, and a large negative at the end (running out of cards) for not having all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CardSetFinder(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        cardset_tot = [10,10],\n",
    "        cardset_goal = [3,3],\n",
    "        hand_limit = 3):\n",
    "        \n",
    "        self.reward_for_set = 3\n",
    "        self.reward_for_invalid_action = -5\n",
    "        self.reward_for_win = 10\n",
    "        self.reward_for_lose = -10\n",
    "        \n",
    "        self.cardset_tot = cardset_tot\n",
    "        self.cardset_goal = cardset_goal\n",
    "        self.hand_limit = hand_limit\n",
    "        self.sets_num = len(self.cardset_tot)\n",
    "        \n",
    "        self.won = False\n",
    "        self.lost = False\n",
    "        \n",
    "        # actions: to discard one of the cards\n",
    "        # we will code it as a discrete 0 to sets_num\n",
    "        # so an action is to discard a type of card, not a specific card\n",
    "        # NB there will be invalid actions, not all of the card types will be in hand all the time\n",
    "        self.action_space = gym.spaces.Discrete(self.sets_num)\n",
    "        \n",
    "        # the states used to be in a table, with three columns, and each row represents a set\n",
    "        # that did not work, and got bad results\n",
    "        # so i am going to unpack it, the state is one long list of numbers\n",
    "        # it is by sets, so first three number belong to first set, etc\n",
    "        # state[set_num * 3 + 0]: number of cards in the deck, lowe limit: 0, upper limit: corresponding cardset_tot\n",
    "        # state[set_num * 3 + 1]: number of cards in the hand, lower limit: 0, upper limit: hand_limit\n",
    "        # state[set_num * 3 + 2]: whether we already have that set collected or not, 0: no, 1: yes\n",
    "        \n",
    "        observation_space_low = \\\n",
    "            [np.array([0,0,0]) for set_num in range(self.sets_num)]\n",
    "        observation_space_low = np.hstack(observation_space_low)\n",
    "        \n",
    "        observation_space_high = \\\n",
    "            [np.array([self.cardset_tot[set_num],self.hand_limit,1]) for set_num in range(self.sets_num)]\n",
    "        observation_space_high = np.hstack(observation_space_high)\n",
    "        \n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low = observation_space_low, \n",
    "            high = observation_space_high, \n",
    "            dtype = int)\n",
    "        \n",
    "        # note: not all the combinations are going to be valid states, \n",
    "        # e.g. if all the cards of a set are in deck, there should not be any in hand, and the set should not be won\n",
    "        \n",
    "    \n",
    "    def create_deck(self):\n",
    "        # creates a list of 0, 1, 2, ... etc in random order\n",
    "        \n",
    "        for i in range(0, self.sets_num):\n",
    "            self.deck += [i] * self.cardset_tot[i]\n",
    "            \n",
    "        random.shuffle(self.deck)\n",
    "        \n",
    "    def draw_cards(self):\n",
    "        # draws cards until hand limit is met, or until we run out of cards\n",
    "        curr_handsize = sum(self.hand)\n",
    "        if curr_handsize < self.hand_limit:\n",
    "            for i in range(curr_handsize, min(self.hand_limit,curr_handsize+len(self.deck))):\n",
    "                self.draw_card()\n",
    "        \n",
    "    def draw_card(self):\n",
    "        # draws the top card from the dack to hand\n",
    "        current_card = self.deck[-1]\n",
    "        self.hand[current_card] += 1\n",
    "        self.deck.pop()\n",
    "\n",
    "    def step(self, action):\n",
    "        \n",
    "        reward = 0\n",
    "        done = False\n",
    "        info = {}\n",
    "\n",
    "        # incoming action is a number between 0 and sets_num\n",
    "        if self.hand[action] == 0:\n",
    "            # does not change anything, just returns invalid action penalty\n",
    "            reward = self.reward_for_invalid_action\n",
    "        else:\n",
    "            # deletes a card from hand\n",
    "            self.discard_card(action)\n",
    "\n",
    "            # checks for set (at this point too, we can find new sets immediately, need to loop\n",
    "            # e.g. as soon as we discard one set, we draw new cards, and it could be that we draw a set            \n",
    "            found_sets = 1\n",
    "            while found_sets > 0:\n",
    "                self.draw_cards()\n",
    "                found_sets = self.check_hand_for_sets()\n",
    "                reward += found_sets * self.reward_for_set\n",
    "            \n",
    "            self.calc_state()\n",
    "            \n",
    "            # at this point, also needs to check if the game is done\n",
    "            self.check_if_won()\n",
    "            if self.won:\n",
    "                reward += self.reward_for_win\n",
    "            self.check_if_lost()\n",
    "            if self.lost:\n",
    "                reward += self.reward_for_lose\n",
    "\n",
    "            done = self.won or self.lost\n",
    "            \n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        \n",
    "        # set parameters to starting position\n",
    "        \n",
    "        # state: in the format of observation_space\n",
    "        # 3 * sets_num number of zeroes\n",
    "        self.state = np.zeros(self.sets_num * 3, dtype = int)\n",
    "        # deck: a list of randomly arranged integers, from 0 to \n",
    "        self.deck = []\n",
    "        self.create_deck()\n",
    "        # hand: a list of sets_num, each element is an integer with the number of cards hold \n",
    "        self.hand = np.zeros(self.sets_num, dtype = int)\n",
    "        \n",
    "        found_sets = 1\n",
    "        while found_sets > 0:\n",
    "            self.draw_cards()\n",
    "            found_sets = self.check_hand_for_sets()\n",
    "            # here, we are not giving rewards, this is the first draw of the game, and sets are automatic\n",
    "        \n",
    "        self.calc_state()\n",
    "        \n",
    "        return self.state\n",
    "    \n",
    "    def check_hand_for_sets(self):\n",
    "        # in the hand set, checks each card type\n",
    "        # sees if we have any that is equal to the limit\n",
    "        # only those sets that are not found yet\n",
    "        \n",
    "        found_sets = 0\n",
    "        \n",
    "        for i in range(0, self.sets_num):\n",
    "            if self.state[i * 3 + 2]==0:\n",
    "                if self.check_hand_for_set(i):\n",
    "                    found_sets +=1\n",
    "                    \n",
    "        return found_sets\n",
    "                \n",
    "    def check_hand_for_set(self, set_num):\n",
    "        set_found = False\n",
    "        if self.hand[set_num] >= self.cardset_goal[set_num]:\n",
    "            # discard those cards from hand\n",
    "            self.hand[set_num] -= self.cardset_goal[set_num]\n",
    "            # set the last element of state as DONE (to 1 from 0)\n",
    "            self.state[set_num * 3 + 2]=1\n",
    "            set_found = True\n",
    "            \n",
    "        return set_found\n",
    "            \n",
    "    def calc_state(self):\n",
    "        # calculates the state variable based on deck list and hand set\n",
    "        # only changes first two columns\n",
    "        # the third one, whether we have already found the set, is handled in the check_hand_for_set\n",
    "        for i in range(0, self.sets_num):\n",
    "            self.state[i * 3 + 0] = self.deck.count(i)\n",
    "            self.state[i * 3 + 1] = self.hand[i]\n",
    "            \n",
    "    def discard_card(self, set_to_discard):\n",
    "        self.hand[set_to_discard] -= 1\n",
    "    \n",
    "    def check_if_won(self):\n",
    "        # the game is won if all the sets are found\n",
    "        # that is, every third value should be 1\n",
    "        self.won = True\n",
    "        for i in range(sets_num):\n",
    "            self.won = self.won and (self.state[i * 3 + 2] == 1)\n",
    "    \n",
    "    def check_if_lost(self):\n",
    "        # the game is lost if not all the sets are found, but we have nothing in the deck\n",
    "        if self.won == False:\n",
    "            self.lose = len(self.deck)==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CardSetFinder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 2, 0, 9, 1, 0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7, 2, 0, 9, 1, 0]), 0, False, {})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, reward, done, info = env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bool"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Testing the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "See if steps work out, cards drawn properly, end states calculated, etc. Does it reduce for incorrect action. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env = CardSetFinder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 1, 0],\n",
       "       [8, 2, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[8, 1, 0],\n",
       "        [8, 2, 0]]), 0, False, {})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[6, 2, 0],\n",
       "        [6, 1, 1]]), 3, False, {})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It's just a series of checking actions, whether they are working properly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In this next bit: check if two sets afterwards are popped in one go. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env = CardSetFinder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 1, 0],\n",
       "       [8, 2, 0]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.hand = [3,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.deck = [1,1,1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "env.state = np.array([[3,0,0],[1,3,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3, 0, 0],\n",
       "        [1, 3, 0]]), -5, False, {})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 1],\n",
       "        [0, 0, 1]]), 16, True, {})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CardSetFinder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines.common.policies import MlpPolicy\n",
    "from stable_baselines import PPO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines.deepq.policies import MlpPolicy\n",
    "from stable_baselines import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines.ppo2.ppo2.PPO2 at 0x7fa8ec26e390>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PPO2(MlpPolicy, env, verbose=False,)\n",
    "model.learn(total_timesteps=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 1 0 8 2 0]\n",
      "0\n",
      "[8 1 0 5 2 1] 3 False\n",
      "1\n",
      "[7 2 0 5 1 1] 0 False\n",
      "0\n",
      "[6 2 0 5 1 1] 0 False\n",
      "0\n",
      "[6 1 0 4 2 1] 0 False\n",
      "0\n",
      "[6 0 0 3 3 1] 0 False\n",
      "1\n",
      "[5 1 0 3 2 1] 0 False\n",
      "1\n",
      "[4 2 0 3 1 1] 0 False\n",
      "1\n",
      "[2 1 1 1 2 1] 13 True\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "print(env.state)\n",
    "for i in range(20):\n",
    "    action, _states = model.predict(obs)\n",
    "    print(action)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    print(obs, rewards, dones)\n",
    "    if dones:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "action, _states = model.predict(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 1, 0, 8, 2, 0])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
